{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week 5 lesson 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamer-dev/coursera-big-data-specialization-notes/blob/master/week_5_lesson_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gtG-5jwh1hXI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DBMS-based and non-DBMS-based Approaches to Big Data\n",
        "\n",
        "In the previous modules, we talked\n",
        "about data variety and streaming data. \n",
        "</br>In this module, we'll focus on a central\n",
        "issue in large scale data processing and management and that is when should\n",
        "we use Hadoop or Yarn style system? And when should we use a database system\n",
        "that can perform parallel operations? And then we'll explore how the state\n",
        "of the art big data management systems address these issues of volume and\n",
        "variety.</br> We start with the problem\n",
        "of **high volume data** and two contrasting approaches for\n",
        "handling them.</br>  So after this lesson, \n",
        "you'll be able to  \n",
        " \n",
        "And briefly describe\n",
        "\n",
        "\n",
        "1.   explain the various advantages of using a DBMS over a file system.\n",
        "2.   Specify the differences between parallel and distributed DBMS.\n",
        "3.   briefly describe \n",
        "\n",
        "\n",
        "a MapReduce-style DBMS and its relationship with the current DBMSs. In the early days,\n",
        "when database systems weren't around or just came in, databases were designed\n",
        "as a set of application programs. They were written to handle data that\n",
        "resided in files in a file system. However, soon this\n",
        "approach led to problems. First, there are multiple file formats. And often, there was a duplication\n",
        "of information in different files. Or the files simply had inconsistent\n",
        "information that was very hard to determine, especially when the data was\n",
        "large and the file content was complex. Secondly, there wasn't\n",
        "a uniform way to access data. Each data access task, like finding\n",
        "employees in a department sorted by their salary versus finding\n",
        "employees in all departments sorted by their start date needed to\n",
        "be written as a separate program. So people ended up writing\n",
        "different programs for data access, as well as data update. A third problem was rooted to\n",
        "the enforcement of constraints, often called integrity constraints. For example, to say something like every\n",
        "employee has exactly one job title. One had arrived that condition,\n",
        "as part of an application program called. So if you want to change the constraint,\n",
        "you need to look for the programs where such\n",
        "a rule is hard coded. The fourth problem has to\n",
        "do with system failures. Supposed Joe, an employee becomes\n",
        "the leader of a group and moves in to the office of the old leader, Ben who has\n",
        "now become the director of the division. So we update Joe's details and\n",
        "move on to update, Ben's new office for the system crashes. So the files are incompletely updated and there is no way to go back,\n",
        "and start all over. The term atomicity means that all of\n",
        "the changes that we need to do for these promotions must happen altogether,\n",
        "as a single unit. They should either fully go through or\n",
        "not go through at all. This atomicity is very difficult to handle\n",
        "when the data reside in one or more files. So, a prime reason for the transition\n",
        "to a DBMS is to alleviate these and other difficulties. If we look at the current DBMS,\n",
        "especially relational DBMS, we will notice a number of advantages. DBMSs offer query languages,\n",
        "which are declarative. Declarative means that we\n",
        "state what we want to retrieve without telling the DBMS\n",
        "how exactly to retrieve it. In a relational DBMS, we can say,\n",
        "find the average set of salary of employees in the R&D division for\n",
        "every job title and sort from high to low. We don't have to tell the system how\n",
        "to group these records by job title or how to extract just the salary field. A typical user of a DBMS who issues\n",
        "queries does not worry about how the relations are structured or whether\n",
        "they are located in the same machine, or spread across five machines. The goal of data independence is to\n",
        "isolate the users from the record layout so long as the logical\n",
        "definition of the data, which means the tables and\n",
        "their attributes are clearly specified. Now most importantly, relational DBMSs\n",
        "have developed a very mature and continually improving methodology of\n",
        "how to answer a query efficiently, even when there are a large\n",
        "number of cables and the number of records\n",
        "exceeds hundreds of millions. From a 2009 account,\n",
        "EB uses the tera data system with 72 machines to manage approximately\n",
        "2.4 terabytes of relational data. These systems have built powerful\n",
        "data structures, algorithms and sound principles to determine how\n",
        "a specific array should be onset efficiently despite the size of the data\n",
        "and the complexity of the tables. Now with any system,\n",
        "bad things can happen. Systems fail in the middle\n",
        "of an operation. Malicious processes try to get\n",
        "unauthorized access to data. One large can often underappreciated\n",
        "aspect of a DBMS is the implementation of transaction\n",
        "safety and failure recovery. Now, recall our discussion of atomicity. In databases, a single logical operation\n",
        "on the data is called a transaction. For example, a transfer of funds\n",
        "from one bank account to another, even involving multiple changes\n",
        "like debiting one account and crediting another is a single transaction. Now, atomicity is one of the four\n",
        "properties that a transaction should provide. The four properties,\n",
        "collectively called ACID are atomicity, consistency, isolation and durability. Consistency means any data\n",
        "written to the database must be valid according to all defined\n",
        "rules including constrains. The durability property ensures that\n",
        "once a transaction has been committed, it will remain so, even in the event\n",
        "of power loss, crashes or errors. The isolation property comes\n",
        "in the context of concurrency, which refers to multiple people\n",
        "updating a database simultaneously. To understand concurrency, think of\n",
        "an airline or a railway reservation system where hundreds and thousands of\n",
        "people are buying, cancelling and changing their reservations and\n",
        "tickets all at the same time. The DBMS must be sure that\n",
        "a ticket should no be sold twice. Or if one person is in the middle\n",
        "of buying the last ticket, another person does not see\n",
        "that ticket as available. These are guaranteed by\n",
        "the isolation property that says, not withstanding the number of people\n",
        "accessing the system at the same time. The transactions must happen as if they're\n",
        "done serially, that is one after another. Providing these capabilities is\n",
        "an important part of the M in DBMS. So next, we consider how traditional\n",
        "databases handle large data volumes. The classical way in which DBMSs\n",
        "have handled the issue of large volumes is by created parallel and\n",
        "distributed databases. In a parallel database, for\n",
        "example, parallel Oracle, parallel DB2 or post SQL XE. The tables are spread across multiple\n",
        "machines and operations like selection, and join use parallel algorithms\n",
        "to be more efficient. These systems also allow a user\n",
        "to create a replication. That is multiple copies of tables. Thus, introducing data redundancy, so that failure on replica can be\n",
        "compensated for by using another. Further, it replicates in\n",
        "sync with each other and a query can result into\n",
        "any of the replicates. This increases the number of simultaneous\n",
        "that is conquer into queries that can be handled by the system. In contrast, a distributed DBMS, which\n",
        "we'll not discuss in detail in this course is a network of independently running\n",
        "DBMSs that communicate with each other. In this case, one component knows some\n",
        "part of the schema of it is neighboring DBMS and can pass a query or part of\n",
        "a query to the neighbor when needed. So the important takeaway issue here is, are all of these facilities\n",
        "offered by a DBMS important for the big data application that\n",
        "you are planning to build? And the answer in many\n",
        "cases can be negative. However, if these issues are important,\n",
        "then the database management systems may offer a viable option for\n",
        "a big data application. Now, let's take a little more time to\n",
        "address an issue that's often discussed in the big data word. The question is if DBMSs are so powerful, why do we see the emergence\n",
        "of MapReduce-style Systems? Unfortunately, the answer to this\n",
        "question is not straightforward. For a long while now, DBMSs have\n",
        "effectively used parallelism, specifically parallel databases in addition to\n",
        "replication would also create partitions. So that different parts of a logical\n",
        "table can physically reside on different machines,, then different parts of a query\n",
        "can access the partitions in parallel and speed up creative performance. Now these algorithms not only improve\n",
        "the operating efficiency, but simultaneously optimize algorithms to\n",
        "take into account the communication cost. That is the time needed to\n",
        "exchange data between machines. However, classical parallel DBMSs did\n",
        "not take into account machine failure. And in contrast, MapReduce was\n",
        "originally developed not for storage and retrieval, but for distributive\n",
        "processing of large amounts of data. Specifically, its goal was to support\n",
        "complex custom computations that could be performed efficiently on many machines. So in a MapReduce or MR setting, the number of machines\n",
        "could go up to thousands. Now since MR implementations were\n",
        "done over Hadoop file systems, issues like node failure were\n",
        "automatically accounted for. So MR effectively used in complex\n",
        "applications like data mining or data clustering, and these algorithms\n",
        "are often very complex, and typically require problem\n",
        "specific techniques. Very often,\n",
        "these algorithms have multiple stages. That is the output from one processing\n",
        "stage is the input to the next. It is difficult to develop these\n",
        "multistage algorithms in a standard relational system. But since these were genetic operations,\n",
        "many of them were designed to work with unstructured data like text and\n",
        "nonstandard custom data formats. Now, it's now amply clear that this\n",
        "mixture of data management requirements and data processing analysis requirements\n",
        "have created an interesting tension in the data management world. Just look at a few of\n",
        "these tension points. Now, DBMSs perform storage and\n",
        "retrieval operations very efficiently. But first,\n",
        "the data must be loaded into the DBMS. So, how much time does loading take? In one study,\n",
        "scientists use two CVS files. One had 92 attributes with\n",
        "about 165 million tuples for a total size of 85 gigabytes. And the other had 227 attributes\n",
        "with 5 million tuples for a total size of 5 gigabytes. The time to load and index this data in\n",
        "MySQL and PostgreSQL, took 15 hours each. In a commercial database running on\n",
        "three machines, it took two hours. Now there are applications like\n",
        "the quantities in the case we discussed earlier where this kind of loading\n",
        "time is simply not acceptable, because the analysis on\n",
        "the data must be performed within a given time limit\n",
        "after it's arrival. A second problem faced by\n",
        "some application is that for them, the DBMSs offer\n",
        "too much functionality. For example, think of an application\n",
        "that only looks at the price of an item if you provide it with a product name or\n",
        "product code. The number of products it serves\n",
        "is let's say, 250 million. This lookup operation happens\n",
        "only on a single table and does not mean anything\n",
        "more complex like a join. Further, consider that while there\n",
        "are several hundred thousand customers who access this data,\n",
        "none of them really update the tables. So, do we need a full function DBMS for\n",
        "this read-only application? Or can we get a simpler solution which\n",
        "can use a cluster of machines, but does not provide all the wonderful\n",
        "guarantees that a DBMS provides? At the other end of the spectrum,\n",
        "there is an emerging class of optimization that meets all the nice transactional\n",
        "guarantees that a DBMS provides. And at the same time, meets the support\n",
        "for efficient analytical operations. These are often required for\n",
        "systems like Real-Time Decision Support. That will accept real-time data like\n",
        "customer purchases on a newly released product will perform some\n",
        "statistical analysis, so that it can determine buying trends. And then decide whether in real-time, a discount can be offered\n",
        "to this customer now. It turns out that the combination\n",
        "of traditional requirements and new requirements is leading\n",
        "to new capabilities, and products in the big data\n",
        "management technology. On the one hand, DBMS technologies\n",
        "are creating new techniques that make use of MapReduce-style data processing. Many of them are being\n",
        "developed to run on HDFS and take advantage of his data\n",
        "replication capabilities. More strikingly, DBMSs are beginning\n",
        "to have a side door for a user to perform and\n",
        "MR-style operation on HDFS files and exchange data between the Hadoop\n",
        "subsystem and the DBMS. Thus, giving the user the flexibility\n",
        "to use both forms of data processing. It has now been recognized\n",
        "that a simple map and reduce operations are not sufficient for\n",
        "many data operations leading to a significant expansion in the number\n",
        "of operations in the MR ecosystems. For example,\n",
        "Spark has several kinds of join and data grouping operations in\n",
        "addition to map and reduce. Sound DBMSs are making use of large distributed memory management\n",
        "operations to accept streaming data. These systems are designed with the idea\n",
        "that the analysis they need to perform on the data are known before. And as new data records arrive,\n",
        "they keep a record of the data in the memory long enough to finish\n",
        "the computation needed on that record. And finally, computer scientists and data scientists are working\n",
        "towards new solutions where large scale distributed algorithms\n",
        "are beginning to emerge to solve different kinds of analytics problems like\n",
        "finding dense regions of a graph. These algorithms use\n",
        "a MR-style computing and are becoming a part of a new\n",
        "generation of DBMS products that invoke these algorithms\n",
        "from inside the database system. In the next video, we'll take a look at\n",
        "some of the modern day data management systems that have some\n",
        "of these capabilities."
      ]
    }
  ]
}